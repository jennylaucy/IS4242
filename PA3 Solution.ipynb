{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "+ Rename this file to `<your nusnetid>.ipynb`. For example, `e0321286.ipynb`.\n",
    "+ The completed assignment must be uploaded to LumiNUS (Files > Assignment Submissions > PA3)\n",
    "+ Submission deadline: 11AM, 9th October\n",
    "+ Late Submission Rules: (1) 10 points will be deducted if submitted after 11 AM, 9th October and before 11 AM, 10th October; (2) Submissions after 11 AM, 10th October will not be graded and will be given **zero** marks.\n",
    "\n",
    "+ This assignment is of 20 marks total. There are two sections I and II.\n",
    "+ The  <font color='purple'> marks </font> associated with each question is mentioned at the end of the question in  <font color='purple'> purple </font> color.\n",
    "+ Questions with <font color='blue'> blue </font> color are not graded, but you are encouraged to answer them for your better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Understanding Grid Search and Pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1) Reimplement lines 2-7 of the code below by making all of the following modifications.** <font color='purple'> (2) </font> \n",
    "\n",
    "(a) Use sklearn's KFold() and find the best estimator using AUC scores obtained in each cross-validation step.\n",
    "\n",
    "(b) Do NOT use GridSearchCV(). You can use Pipeline(). \n",
    "\n",
    "Select the best combination of hyperparameters based on 3-fold cross-validation scores. \n",
    "\n",
    "Print the average AUC score for each cross-validation fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__C': 1, 'pca__n_components': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "X,Y = make_classification(n_samples=100, n_features=20, n_informative=10, n_redundant=10, n_classes=2, n_clusters_per_class=1, shift=2,scale=None, random_state=0)\n",
    "#2\n",
    "parameters = dict(pca__n_components=[5,8],lr__C=[1, 3])\n",
    "#3\n",
    "estA = Pipeline(steps=[('pca', PCA()), ('lr', LogisticRegression())])\n",
    "#4\n",
    "estimator_A = GridSearchCV(estA, parameters, cv=3, scoring = 'roc_auc')\n",
    "#5\n",
    "estimator_A.fit(X,Y)\n",
    "#6\n",
    "A = estimator_A.best_estimator_\n",
    "#7\n",
    "print(estimator_A.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8908179012345679, 0.9488425925925926, 0.8908179012345679, 0.942746913580247]\n",
      "Best parameters: PCA 8 components, LR C=1 or C=3\n"
     ]
    }
   ],
   "source": [
    "A = Pipeline(steps=[('pca', PCA(n_components=5)), ('lr', LogisticRegression(C=1))])\n",
    "B = Pipeline(steps=[('pca', PCA(n_components=8)), ('lr', LogisticRegression(C=1))])\n",
    "C = Pipeline(steps=[('pca', PCA(n_components=5)), ('lr', LogisticRegression(C=3))])\n",
    "D = Pipeline(steps=[('pca', PCA(n_components=8)), ('lr', LogisticRegression(C=3))])\n",
    "\n",
    "ascores, bscores, cscores, dscores = [],[],[],[]\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "#Grid search is a brute-force approach that trains and tests each estimator \n",
    "#on all folds and chooses the best scoring estimator's combination of parameters\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    A.fit(X_train, y_train)\n",
    "    y_pred = A.predict_proba(X_test)[:,1]\n",
    "    ascores.append(roc_auc_score(y_test,y_pred))\n",
    "    \n",
    "    B.fit(X_train, y_train)\n",
    "    y_pred = B.predict_proba(X_test)[:,1]\n",
    "    bscores.append(roc_auc_score(y_test,y_pred))\n",
    "    \n",
    "    C.fit(X_train, y_train)\n",
    "    y_pred = C.predict_proba(X_test)[:,1]\n",
    "    cscores.append(roc_auc_score(y_test,y_pred))\n",
    "    \n",
    "    D.fit(X_train, y_train)\n",
    "    y_pred = D.predict_proba(X_test)[:,1]\n",
    "    dscores.append(roc_auc_score(y_test,y_pred))\n",
    "    \n",
    "print([np.mean(x) for x in [ascores, bscores, cscores, dscores]])\n",
    "print('Best parameters: PCA 8 components, LR C=1 or C=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MS**\n",
    "+ 1.5 mark for correct implementaion, i.e. with 4 different classifiers.\n",
    "+ 0.5 mark printing the correct best parameters.\n",
    "+ 0 mark if grid search CV is not implemented correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2) Reimplement lines 2 and 3 of the code below by making all of the following modifications.** <font color='purple'> (2) </font> \n",
    "\n",
    "(a) Use fit() and transform() for each operation in the pipeline\n",
    "\n",
    "(b) Use KFold() and find the mean and standard deviation of AUC scores obtained over the 3 folds\n",
    "\n",
    "(c) Do NOT use the Pipeline() object or cross_val_score() function\n",
    "\n",
    "Ensure that there is no data leakage. \n",
    "\n",
    "Print the AUC score in each fold and the mean and standard deviation of AUC scores over the 3 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98269896 0.90441176 0.96323529] 0.9501153402537486 0.03327983578332014\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "X,Y = make_classification(n_samples=100, n_features=20, n_informative=10, n_redundant=10, n_classes=2, n_clusters_per_class=1, shift=2,scale=None, random_state=0)\n",
    "#2\n",
    "estA = Pipeline(steps=[('pca', PCA()), ('lr', LogisticRegression())])\n",
    "#3\n",
    "scores = cross_val_score(estA, X, Y, cv=3, scoring='roc_auc')\n",
    "#4\n",
    "print(scores, np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96875, 0.9074074074074074, 0.9703703703703704] 0.9488425925925926 0.029306567279163854\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "#To obtain the cross-validation score of an estimator, the estimator's pipeline is\n",
    "#evaluated by training and testing each step of the pipeline on all folds \n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    #fit PCA on training data, transform data, then fit LR\n",
    "    #if pca.fit() is called on entire X, there is data leakage:\n",
    "    #only training data (within each fold) should be used to fit PCA and LR \n",
    "    pca = PCA(n_components=8)\n",
    "    pca.fit(X_train)\n",
    "    X1 = pca.transform(X_train)\n",
    "    LR = LogisticRegression(C=1)\n",
    "    LR.fit(X1,y_train)\n",
    "    \n",
    "    #use PCA loadings from train data to transform test data, then predict using LR\n",
    "    #if pca.transform() not used before LR.predict() -> Pipeline is incorrectly implemented\n",
    "    y_pred = LR.predict_proba(pca.transform(X_test))[:,1]\n",
    "    scores.append(roc_auc_score(y_test,y_pred))\n",
    "\n",
    "print(scores, np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MS**\n",
    "+ 0 marks if `fit` and `transform` is not for both `pca` and `LR`.\n",
    "+ deduct 1.5 mark if data leakage happens, i.e. if entire X is used for fitting pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3) Evaluate the performance of the model from question 2 (trained on X,Y)  on the test set (X2) generated below. Use metrics precision, recall, sensitivity, specificiy and AUC.** <font color='purple'> (0.5) </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2,Y2 = make_classification(n_samples=500, n_features=20, n_informative=10, n_redundant=10, n_classes=2, n_clusters_per_class=1, shift=2,scale=None, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5021441372247823\n",
      "0.6854838709677419 0.30952380952380953\n",
      "0.5 0.30952380952380953\n"
     ]
    }
   ],
   "source": [
    "#cross validation error is an estimate of test error and is typically used to \n",
    "#choose a model (and its hyperparameters) using training data \n",
    "est = Pipeline(steps=[('pca', PCA(n_components=8)), ('lr', LogisticRegression(C=1))])\n",
    "est.fit(X,Y)\n",
    "\n",
    "#After choosing the model, the entire training data can be used to train and deployed to\n",
    "#predict on the \"unseen\" test data\n",
    "ypred = est.predict_proba(X2)[:,1]\n",
    "print(roc_auc_score(Y2, ypred))\n",
    "\n",
    "ypred = est.predict(X2)\n",
    "c = confusion_matrix(Y2,ypred) #[[TN FP],[FN,TP]]\n",
    "tn, fp, fn, tp = c.ravel()\n",
    "sens, spec = tp/(tp+fn), tn/(tn+fp) #c[0][0]/(c[0][0]+c[0][1]), c[1][1]/(c[1][1]+c[1][0])\n",
    "print(spec, sens)\n",
    "print(precision_score(Y2, ypred), recall_score(Y2, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MS**\n",
    "+ 0.1 mark for each metric implemented correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Kaggle Competition\n",
    "In this section, we will attempt a relatively simple Kaggle competition: Porto Seguro's Safe Driver Prediction. The aim is to predict if a driver will file an insurance claim next year. Please read the description of the challenge on [Kaggle](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction). The competition is closed and we cannot participate in it. So, we'll just use the training data provided in this assignment.  \n",
    "\n",
    "Create a Kaggle account (if you don't have one) and download `train.csv` from the Data tab on the competition webpage. Read the Data description carefully. We'll build and evaluate end-to-end machine learning pipelines using sklearn functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4) Data Loading** <font color='purple'> (2) </font> \n",
    "\n",
    "(i) Load the data into a dataframe `df`, and print the number of observations (rows). This is a big dataset, so use the following code to sample only 1% of the observations using the code:`df = df.sample(frac=0.01, random_state=0)`. </font>  <font color='purple'> (0.5) </font> \n",
    "\n",
    "Use this sampled data for all the remaining questions in this section. **Make sure you set `random_state=0`, so your code can be reproduced exactly.** Then separate the target variable `Y` from the predictors `X`. Note that the `id` is not a predictor. <font color='blue'> Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "(ii) Print the number of classes in the target variable, and number of observations available in each class. <font color='purple'> (0.5) </font> \n",
    "    \n",
    "(iii) Split the data for training (80%) (`X_train, Y_train`) and testing (20%) (`X_test, Y_test`). Print the number of observations in the training set. <font color='purple'> (0.5) </font> \n",
    "    \n",
    "(iv) The features in this dataset are heterogeneous. Look at the column names and make separate lists of names for categorical (nominal) features `cat_feat`, binary features `bin_feat`, and numerical features (continuous and ordinal features) `num_feat`. Note that, in this analysis, we are considering binary features separately, not as part of categorical or numerical. Print the number of features in each of these 3 lists. <font color='purple'> (0.5) </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495179</th>\n",
       "      <td>1237354</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210156</th>\n",
       "      <td>525008</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170340</th>\n",
       "      <td>425680</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462495</th>\n",
       "      <td>1156017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6892</th>\n",
       "      <td>17538</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "495179  1237354       0          5              1          4              0   \n",
       "210156   525008       0          5              1          5              0   \n",
       "170340   425680       0          2              1          6              1   \n",
       "462495  1156017       0          2              1          1              0   \n",
       "6892      17538       0          2              1          7              0   \n",
       "\n",
       "        ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "495179              0              0              1              0  ...   \n",
       "210156              0              1              0              0  ...   \n",
       "170340              0              1              0              0  ...   \n",
       "462495              0              0              0              1  ...   \n",
       "6892                4              1              0              0  ...   \n",
       "\n",
       "        ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "495179           7           2           8           4               0   \n",
       "210156           5           2           0           9               0   \n",
       "170340           4           2           3          10               0   \n",
       "462495          12           3           5           6               0   \n",
       "6892             5           1           3           6               0   \n",
       "\n",
       "        ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "495179               0               0               0               0   \n",
       "210156               1               1               0               1   \n",
       "170340               0               0               1               1   \n",
       "462495               1               1               0               0   \n",
       "6892                 1               1               0               1   \n",
       "\n",
       "        ps_calc_20_bin  \n",
       "495179               0  \n",
       "210156               0  \n",
       "170340               1  \n",
       "462495               0  \n",
       "6892                 1  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df.sample(frac=0.01, random_state=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5740\n",
       "1     212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['id', 'target'])\n",
    "Y = df['target']\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4761, 57)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)\n",
    "# To make some operations convinient we convert X_train as a dataframe\n",
    "X_train = pd.DataFrame(data=X_train, columns=X.columns)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categorical features = 14\n",
      "# binary features = 17\n",
      "# numerical features = 26\n",
      "['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin']\n"
     ]
    }
   ],
   "source": [
    "cat_features = [f for f in X.columns if f.endswith('cat')]\n",
    "bin_features = [f for f in X.columns if f.endswith('bin')]\n",
    "num_features = [f for f in X.columns if f not in cat_features+bin_features]\n",
    "print('# categorical features =', len(cat_features))\n",
    "print('# binary features =', len(bin_features))\n",
    "print('# numerical features =', len(num_features))\n",
    "print(bin_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MS**  \n",
    "(i) If id is part of `X` then assign 0 mark.  \n",
    "(ii) 0.25 for each.  \n",
    "(iii) Full mark if correct.  \n",
    "(iv) For each wrong list deduct 0.2 mark; if all 3 are wrong, assign 0 mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5) Preprocessing** <font color='purple'> (3) </font>  \n",
    "\n",
    "Create a `preprocessor` pipeline with the following transformation steps.\n",
    "\n",
    "(i) \"Appropriate\" *Imputers* for different types of data (categorical, binary and numerical). <font color='purple'> (1) </font> \n",
    "\n",
    "(ii) A *OneHotEncoder* for the categorical features to convert their integer representations to one-hot-vectors. <font color='purple'> (1) </font> \n",
    "\n",
    "(iii) A *Scaler* for standardising the resulting data from the above two steps. <font color='purple'> (0.5) </font>\n",
    "\n",
    "(iv) Print the total number of features after transforming `X_train` with the above constructed `preprocessor`. <font color='purple'> (0.5) </font>\n",
    "\n",
    "\n",
    "Hint: Use `ColumnTransformer` to consolidate first two steps.\n",
    "\n",
    "Note: Only the `preprocessor` Pipeline object should be used to `fit` and `transform` the training data. The constituent objects (Imputer, OneHotEncoder and Scaler) should not be separately used to `fit` and `transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imp = SimpleImputer(missing_values=-1, strategy='median')\n",
    "bin_imp = SimpleImputer(missing_values=-1, strategy='most_frequent')\n",
    "cat_imp = SimpleImputer(missing_values=-1, strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of output features: 218\n"
     ]
    }
   ],
   "source": [
    "oh_enc = OneHotEncoder(categories='auto', sparse=False, handle_unknown='ignore')\n",
    "cat_transformer = Pipeline(steps=[('imputer', cat_imp), \n",
    "                                  ('onehot', oh_enc)])\n",
    "\n",
    "col_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_imp, num_features), \n",
    "        ('bin', bin_imp, bin_features),\n",
    "        ('cat', cat_transformer, cat_features)])\n",
    "\n",
    "scaler = StandardScaler(with_std=True)\n",
    "preprocessor = Pipeline(steps=[('col_trans', col_transformer),\n",
    "                               ('scaler', scaler)])\n",
    "preprocessor.fit(X_train)\n",
    "X_train_preprocessed = preprocessor.transform(X_train)\n",
    "print(\"Total number of output features:\", X_train_preprocessed.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MS**  \n",
    "(i) For binary and categrical variables, mode (most frequent) based impuation should be followed. Otherwise assign 0 marks.  \n",
    "(ii) 0 for wrong implementation.  \n",
    "(iii) 0 for wrong implementation.  \n",
    "(iv) should be 218 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6) Building Different Estimators**\n",
    "\n",
    "Build four different estimators using `preprocessor` of previous question and the following pipelines of operations:\n",
    "\n",
    "1. `est1`: Preprocessing -> Classification <font color='purple'> (1.5) </font> \n",
    "2. `est2`: Preprocessing -> Feature Selection -> Classification <font color='purple'> (1.75) </font> \n",
    "3. `est3`: Preprocessing -> Feature Selection -> PCA -> Classification <font color='purple'> (2) </font> \n",
    "4. `est4`: Preprocessing -> PCA -> Classification <font color='purple'> (1.75) </font> \n",
    "\n",
    "The four estimators should differ in one or more functions chosen for feature selection and/or classification (e.g. you could use [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest) and LogisticRegression in `est2`, and [VarianceThreshold](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold) and LogisticRegression in `est3`. You are free to use any classiffier or [feature selection method](https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection) from sklearn (not just the ones listed above or discussed in class) that can be used in these pipelines.\n",
    "\n",
    "Identify at least one hyperparameter per operation in each pipeline. For each selected hyperparameters, choose two values -- they may or may not be the same across pipelines. Use grid search over the hyperparameter values with 5-fold crossvalidation and `roc_auc` scoring. Evaluate the four best estimators over 5-fold cross validation on the training data. Print the mean and std of AUC over the 5-folds for each best estimator. \n",
    "\n",
    "<font color='blue'> Among the 4 best estimators found above, which has highest AUC score? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to make the notebook look cleaner\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC mean = 0.532; AUC std = 0.022\n"
     ]
    }
   ],
   "source": [
    "p1 = Pipeline(steps=[('preprocessor', preprocessor), ('lr', LogisticRegression(solver='lbfgs'))])\n",
    "hyperparameters = {'preprocessor__col_trans__num__strategy':['mean', 'most_frequent']}\n",
    "est1 = GridSearchCV(p1, hyperparameters, cv=5, scoring='roc_auc')\n",
    "est1.fit(X_train,Y_train)\n",
    "best_est1 = est1.best_estimator_\n",
    "scores = cross_val_score(best_est1, X_train,Y_train, cv=5, scoring='roc_auc')\n",
    "print(\"AUC mean = {:.3f}; AUC std = {:.3f}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC mean = 0.535; AUC std = 0.024\n"
     ]
    }
   ],
   "source": [
    "p2 = Pipeline(steps=[('preprocessor', preprocessor), ('fsel', SelectKBest()), ('knn', KNeighborsClassifier())])\n",
    "hyperparameters = {'preprocessor__col_trans__num__strategy':['mean', 'most_frequent'],\n",
    "                   'fsel__k': [30, 50], \n",
    "                   'knn__n_neighbors':[3,5]}\n",
    "est2 = GridSearchCV(p2, hyperparameters, cv=5, scoring='roc_auc')\n",
    "est2.fit(X_train,Y_train)\n",
    "best_est2 = est2.best_estimator_\n",
    "scores = cross_val_score(best_est2, X_train, Y_train, cv=5, scoring='roc_auc')\n",
    "print(\"AUC mean = {:.3f}; AUC std = {:.3f}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC mean = 0.542; AUC std = 0.027\n"
     ]
    }
   ],
   "source": [
    "p3 = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                     ('fsel', SelectKBest()), \n",
    "                     ('pca', PCA()), \n",
    "                     ('knn', KNeighborsClassifier())])\n",
    "hyperparameters = {'preprocessor__col_trans__num__strategy':['mean', 'most_frequent'],\n",
    "                   'fsel__k': [30, 50], \n",
    "                   'pca__n_components': [10,20],\n",
    "                   'knn__n_neighbors':[3,5]}\n",
    "est3 = GridSearchCV(p3, hyperparameters, cv=5, scoring='roc_auc')\n",
    "est3.fit(X_train,Y_train)\n",
    "best_est3 = est3.best_estimator_\n",
    "scores = cross_val_score(best_est3, X_train, Y_train, cv=5, scoring='roc_auc')\n",
    "print(\"AUC mean = {:.3f}; AUC std = {:.3f}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC mean = 0.515; AUC std = 0.012\n"
     ]
    }
   ],
   "source": [
    "p4 = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                     ('pca', PCA()), \n",
    "                     ('knn', KNeighborsClassifier())])\n",
    "hyperparameters = {'preprocessor__col_trans__num__strategy':['mean', 'most_frequent'],\n",
    "                   'pca__n_components': [10,20],\n",
    "                   'knn__n_neighbors':[3,5]}\n",
    "est4 = GridSearchCV(p4, hyperparameters, cv=5, scoring='roc_auc')\n",
    "est4.fit(X_train,Y_train)\n",
    "best_est4 = est4.best_estimator_\n",
    "scores = cross_val_score(best_est4, X_train, Y_train, cv=5, scoring='roc_auc')\n",
    "print(\"AUC mean = {:.3f}; AUC std = {:.3f}\".format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MS**  \n",
    "For each `est`:\n",
    "+ Correct Implementation of pipeline => 0.5 marks\n",
    "+ Hyperparameter tuning => 1 mark; \n",
    "\n",
    "Deduct marks in the following cases:\n",
    "+ If classifiers of `est1` and `est4` are same, then deduct 1 mark (0.5 for each question).\n",
    "+ If classifiers **and** features selector are same in `est2` and `est3`, then deduct 1 mark (0.5 for each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7) Class Imbalance** <font color='purple'> (3.5) </font> \n",
    "\n",
    "Learn what is class imbalance by reading [this article](https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28). \n",
    "\n",
    "Additional links to packages for handling class imbalance in python: [Imbalanced-learn.org](http://imbalanced-learn.org/en/stable/index.html), [Over-sampling](http://imbalanced-learn.org/en/stable/over_sampling.html#a-practical-guide), [Under-sampling](http://imbalanced-learn.org/en/stable/under_sampling.html).\n",
    "\n",
    "Install the `imbalanced-learn` package within Anaconda (See installation details in the link given above). We'll denote the estimator with the best average AUC in the previous question by `M`. \n",
    "\n",
    "+ Print the `accuracy_score`, `precision_score`, `recall_score` and `confusion_matrix` of `M` on the test dataset. <font color='purple'> (0.5) </font>  \n",
    "<font color='blue'> In this case, dose high accuracy score reflect better performance? </font> \n",
    "\n",
    "+ Create two more estimators\n",
    "    1. `M_over`\n",
    "    2. `M_under`  \n",
    "    \n",
    "  by adding \n",
    "  \n",
    "    1. SMOTE \n",
    "    2. under-sampler\n",
    "    \n",
    "    respectively to the preprocessing pipeline (just before scaling transformation) of M.\n",
    "    \n",
    "    Note that for this you may have to use the [Pipeline object](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.pipeline.Pipeline.html) in imbalanced-learn.\n",
    "\n",
    "    Train both these estimators on the training data. \n",
    "\n",
    "    Print the mean and standard deviation of the AUC values, over the 5 folds, for each estimator on the training data.\n",
    "\n",
    "    Print the accuracy_score, precision, recall and confusion_matrix of `M_over` and `M_under` on the test data. <font color='purple'> (3) </font>  \n",
    "\n",
    "<font color='blue'> How does SMOTE or under-sampling impact (increase/decrease) the learning performance on training and test data as compared to `M`? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 96.22%\n",
      "precision: 0.00%; recall: 0.00%\n",
      "[[1146    1]\n",
      " [  44    0]]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = best_est3.predict(X_test)\n",
    "print(\"test accuracy = {:.2%}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"precision: {:.2%}; recall: {:.2%}\".format(precision_score(Y_test, Y_pred), \n",
    "                                                 recall_score(Y_test, Y_pred)))\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as Pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fsel__k': 30,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'pca__n_components': 20,\n",
       " 'preprocessor__col_trans__num__strategy': 'most_frequent'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fsel__k': 30,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'pca__n_components': 20,\n",
       " 'col_trans__num__strategy': 'most_frequent'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_params = est3.best_params_.copy()\n",
    "M_params['col_trans__num__strategy'] = M_params['preprocessor__col_trans__num__strategy']\n",
    "del M_params['preprocessor__col_trans__num__strategy']\n",
    "M_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampling:\n",
      "-----------\n",
      "AUC mean = 0.500; AUC std = 0.026\n",
      "test accuracy = 82.96%\n",
      "precision: 5.08%; recall: 20.45%\n",
      "[[979 168]\n",
      " [ 35   9]]\n",
      "\n",
      "Undersampling:\n",
      "-----------\n",
      "AUC mean = 0.543; AUC std = 0.028\n",
      "test accuracy = 51.30%\n",
      "precision: 3.79%; recall: 50.00%\n",
      "[[589 558]\n",
      " [ 22  22]]\n"
     ]
    }
   ],
   "source": [
    "M_over = Pipe(steps=[('col_trans', col_transformer),\n",
    "                     ('over', SMOTE()),\n",
    "                     ('scaler', scaler),\n",
    "                     ('fsel', SelectKBest()), \n",
    "                     ('pca', PCA()), \n",
    "                     ('knn', KNeighborsClassifier())])\n",
    "M_over.set_params(**M_params)\n",
    "M_over.fit(X_train, Y_train)\n",
    "scores = cross_val_score(M_over, X_train, Y_train, cv=5, scoring='roc_auc')\n",
    "print(\"Oversampling:\\n-----------\")\n",
    "print(\"AUC mean = {:.3f}; AUC std = {:.3f}\".format(np.mean(scores), np.std(scores)))\n",
    "Y_pred = M_over.predict(X_test)\n",
    "print(\"test accuracy = {:.2%}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"precision: {:.2%}; recall: {:.2%}\".format(precision_score(Y_test, Y_pred), \n",
    "                                                 recall_score(Y_test, Y_pred)))\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "M_under = Pipe(steps=[('col_trans', col_transformer),\n",
    "                      ('under', RandomUnderSampler(random_state=0, replacement=True)),\n",
    "                      ('scaler', scaler),\n",
    "                      ('fsel', SelectKBest()), \n",
    "                      ('pca', PCA()), \n",
    "                      ('knn', KNeighborsClassifier())])\n",
    "M_under.set_params(**M_params)\n",
    "M_under.fit(X_train, Y_train)\n",
    "scores = cross_val_score(M_under, X_train, Y_train, cv=5, scoring='roc_auc')\n",
    "print(\"\\nUndersampling:\\n-----------\")\n",
    "print(\"AUC mean = {:.3f}; AUC std = {:.3f}\".format(np.mean(scores), np.std(scores)))\n",
    "Y_pred = M_under.predict(X_test)\n",
    "print(\"test accuracy = {:.2%}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"precision: {:.2%}; recall: {:.2%}\".format(precision_score(Y_test, Y_pred), \n",
    "                                                 recall_score(Y_test, Y_pred)))\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MS**\n",
    "+ 0.5 for printing the metrics on the test data. 0 marks if computed on training data. \n",
    "+ Except AUC, all the metrics should be computed on test data. Otherwise deduct 1 mark for each estimator `M_over` and `M_under`.\n",
    "+ The hyper parameters of `M_over` and `M_under` should be same as that of `M`. Otherwise deduct 1 mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8) Ensemble Method**  <font color='purple'> (1) </font> \n",
    "\n",
    "To answer this question, learn about Random Forest Classifier. You may follow these links:\n",
    "[Understanding Random Forest](https://towardsdatascience.com/understanding-random-forest-58381e0602d2), and [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). \n",
    "\n",
    "+ Create a pipeline with the `preprocessor` object of Q5 and a RandomForest classifier having 100 estimators and a maximum depth of 3. Train it on the training set. \n",
    "\n",
    "    Print the `accuracy_sore`, precision, recall and `confusion_matrix` of this model on the test data. <font color='purple'> (1) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC mean = 0.608; AUC std = 0.043\n",
      "test accuracy = 96.31%\n",
      "precision: 0.00%; recall: 0.00%\n",
      "[[1147    0]\n",
      " [  44    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                        ('rf', RandomForestClassifier(n_estimators=100, max_depth=3))])\n",
    "rfclf.fit(X_train, Y_train)\n",
    "scores = cross_val_score(rfclf, X_train, Y_train, cv=5, scoring='roc_auc')\n",
    "print(\"AUC mean = {:.3f}; AUC std = {:.3f}\".format(np.mean(scores), np.std(scores)))\n",
    "Y_pred = rfclf.predict(X_test)\n",
    "print(\"test accuracy = {:.2%}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(\"precision: {:.2%}; recall: {:.2%}\".format(precision_score(Y_test, Y_pred), \n",
    "                                                 recall_score(Y_test, Y_pred)))\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MS**\n",
    "+ 0.25 marks for each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
